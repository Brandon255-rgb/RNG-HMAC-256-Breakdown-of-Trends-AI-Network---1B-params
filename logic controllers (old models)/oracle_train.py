#!/usr/bin/env python3
"""
SUPREME PATTERN ORACLE - CONSOLIDATED MODEL ENGINE
=================================================

The ultimate consolidated AI that combines all prediction methods into one file.
Integrates with Supreme Bedrock Bot and main dashboard system.

STREAMLINED FEATURES:
- 3XOR Control Method with Bitcoin-miner logic
- Top 10 Elite Pattern Recognition Methods  
- One-time training on 1 billion rolls (rolls_1e9.u16)
- Persistent model storage (supreme_oracle.pth, scaler.pkl, patterns.json)
- GPU-accelerated pattern mining
- Weighted ensemble predictions
- Seamless integration with dashboard and Bedrock bot
- HMAC-SHA256 analysis with session seeds
- Real-time prediction with confidence scoring
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.cuda as cuda
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, accuracy_score
from sklearn.model_selection import train_test_split
from scipy.stats import entropy, pearsonr, spearmanr
from collections import Counter, defaultdict
from typing import Optional, Dict, List, Tuple, Any
import joblib
import pickle
import json
import hashlib
import hmac
import time
import logging
import os
from pathlib import Path
from typing import Dict, List, Tuple, Any
import matplotlib.pyplot as plt
import seaborn as sns

# Configure GPU if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ðŸ”¥ Using device: {device}")

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HMACAnalyzer:
    """Advanced HMAC analysis for Stake dice predictions"""
    
    def __init__(self):
        self.cache = {}
        
    def calculate_stake_result(self, client_seed: str, server_seed: str, nonce: int) -> float:
        """Calculate exact Stake dice result using HMAC-SHA256"""
        # Create cache key
        cache_key = f"{client_seed}:{server_seed}:{nonce}"
        if cache_key in self.cache:
            return self.cache[cache_key]
            
        # Calculate HMAC
        message = f"{client_seed}:{nonce}"
        hash_value = hmac.new(
            server_seed.encode('utf-8'),
            message.encode('utf-8'),
            hashlib.sha256
        ).hexdigest()
        
        # Convert to dice result
        result = self.hash_to_dice_result(hash_value)
        
        # Cache result
        self.cache[cache_key] = result
        return result
    
    def hash_to_dice_result(self, hash_value: str) -> float:
        """Convert HMAC hash to dice result (0-100)"""
        # Take first 8 characters of hash
        hex_substr = hash_value[:8]
        
        # Convert to integer
        int_value = int(hex_substr, 16)
        
        # Convert to 0-100 range with high precision
        result = (int_value / (2**32)) * 100
        
        return round(result, 4)
    
    def generate_prediction_sequence(self, client_seed: str, server_seed: str, 
                                   start_nonce: int, count: int = 50) -> List[Dict]:
        """Generate sequence of predictions"""
        predictions = []
        
        for i in range(count):
            nonce = start_nonce + i
            result = self.calculate_stake_result(client_seed, server_seed, nonce)
            
            predictions.append({
                'nonce': nonce,
                'predicted_result': result,
                'confidence': 100.0,  # HMAC is deterministic
                'method': 'hmac_exact'
            })
            
        return prediction
    
    def get_supreme_prediction(self, client_seed: str = None, server_seed: str = None, 
                              nonce: int = None, count: int = 10) -> Dict:
        """
        Get supreme prediction using all available methods
        """
        if client_seed and server_seed and nonce:
            # Use exact HMAC calculation
            hmac_predictions = self.hmac_analyzer.generate_prediction_sequence(
                client_seed, server_seed, nonce, count
            )
            
            # Get pattern-based predictions if we have historical data
            pattern_predictions = []
            if len(self.historical_results) > 50:
                pattern_predictions = self._get_ensemble_prediction(count)
            
            # Combine predictions
            combined_predictions = []
            for i in range(count):
                pred = {
                    'nonce': nonce + i,
                    'hmac_result': hmac_predictions[i]['predicted_result'] if i < len(hmac_predictions) else None,
                    'pattern_result': pattern_predictions[i]['predicted_result'] if i < len(pattern_predictions) else None,
                    'confidence': 95.0,  # High confidence with HMAC
                    'method': 'supreme_combined'
                }
                
                # Use HMAC as primary, pattern as validation
                if pred['hmac_result'] is not None:
                    pred['predicted_result'] = pred['hmac_result']
                    if pred['pattern_result'] is not None:
                        # Boost confidence if pattern agrees
                        diff = abs(pred['hmac_result'] - pred['pattern_result'])
                        if diff < 10:
                            pred['confidence'] = 99.0
                else:
                    pred['predicted_result'] = pred['pattern_result']
                    pred['confidence'] = 75.0
                
                combined_predictions.append(pred)
            
            return {
                'predictions': combined_predictions,
                'method': 'supreme_combined',
                'using_real_seeds': True,
                'total_predictions': count
            }
        else:
            # Use default seeds and pattern-based prediction
            return self._get_ensemble_prediction(count)
    
    def _get_ensemble_prediction(self, count: int = 10) -> List[Dict]:
        """Get ensemble prediction using multiple methods"""
        if len(self.historical_results) < 50:
            return self._generate_default_predictions(count)

        data = np.array(self.historical_results[-100:])  # Use last 100 results
        predictions = []
        
        # Define prediction methods for this instance
        prediction_methods = [
            self._fourier_prediction,
            self._wavelet_prediction, 
            self._trend_prediction,
            self._autocorr_prediction,
            self._neural_prediction
        ]

        for i in range(count):
            method_predictions = []
            
            # Run all prediction methods
            for method in prediction_methods:
                try:
                    pred = method(data, i)
                    if pred is not None and 0 <= pred <= 100:
                        method_predictions.append(pred)
                except Exception as e:
                    logger.warning(f"Prediction method failed: {e}")
            
            if method_predictions:
                # Weighted ensemble
                final_prediction = np.mean(method_predictions)
                confidence = min(80.0, len(method_predictions) * 15)  # More methods = higher confidence
                
                predictions.append({
                    'predicted_result': float(final_prediction),
                    'confidence': confidence,
                    'method': 'ensemble',
                    'contributing_methods': len(method_predictions)
                })
            else:
                # Fallback prediction
                predictions.append({
                    'predicted_result': 50.0,
                    'confidence': 30.0,
                    'method': 'fallback',
                    'contributing_methods': 0
                })
        
        return predictions
    
    def _fourier_prediction(self, data: np.ndarray, steps_ahead: int) -> Optional[float]:
        """Fourier-based prediction"""
        try:
            from scipy.fft import fft, ifft
            
            # Apply FFT
            fft_data = fft(data)
            
            # Keep only low frequencies (smooth trend)
            cutoff = len(data) // 4
            fft_data[cutoff:-cutoff] = 0
            
            # Inverse FFT to get smoothed signal
            smoothed = np.real(ifft(fft_data))
            
            # Linear extrapolation based on trend
            trend = smoothed[-1] - smoothed[-5]
            prediction = smoothed[-1] + trend * (steps_ahead + 1)
            
            return np.clip(prediction, 0, 100)
            
        except ImportError:
            return None
    
    def _wavelet_prediction(self, data: np.ndarray, steps_ahead: int) -> Optional[float]:
        """Wavelet-based prediction (simplified)"""
        try:
            # Simple moving average with different windows
            short_ma = np.mean(data[-5:])
            medium_ma = np.mean(data[-15:])
            long_ma = np.mean(data[-30:])
            
            # Weighted combination
            weights = [0.5, 0.3, 0.2]
            prediction = weights[0] * short_ma + weights[1] * medium_ma + weights[2] * long_ma
            
            return np.clip(prediction, 0, 100)
            
        except Exception:
            return None
    
    def _trend_prediction(self, data: np.ndarray, steps_ahead: int) -> Optional[float]:
        """Trend-based prediction"""
        try:
            if len(data) < 10:
                return None
                
            x = np.arange(len(data))
            z = np.polyfit(x, data, 2)  # Quadratic fit
            p = np.poly1d(z)
            
            # Predict next value
            next_x = len(data) + steps_ahead
            prediction = p(next_x)
            
            return np.clip(prediction, 0, 100)
            
        except Exception:
            return None
    
    def _autocorr_prediction(self, data: np.ndarray, steps_ahead: int) -> Optional[float]:
        """Autocorrelation-based prediction"""
        try:
            # Find best lag correlation
            best_lag = 1
            best_corr = 0
            
            for lag in range(1, min(20, len(data)//2)):
                if lag < len(data):
                    corr = np.corrcoef(data[:-lag], data[lag:])[0, 1]
                    if not np.isnan(corr) and abs(corr) > abs(best_corr):
                        best_corr = corr
                        best_lag = lag
            
            # Use lag to predict
            if best_lag < len(data):
                lag_index = -(best_lag + steps_ahead)
                if abs(lag_index) < len(data):
                    prediction = data[lag_index]
                    return np.clip(prediction, 0, 100)
                    
        except Exception:
            pass
            
        return None
    
    def _neural_prediction(self, data: np.ndarray, steps_ahead: int) -> Optional[float]:
        """Simple neural network prediction"""
        try:
            if len(data) < 20:
                return None
                
            # Prepare data for simple neural network
            sequence_length = 10
            X, y = [], []
            
            for i in range(sequence_length, len(data)):
                X.append(data[i-sequence_length:i])
                y.append(data[i])
            
            if len(X) < 5:
                return None
                
            X, y = np.array(X), np.array(y)
            
            # Simple linear regression as neural network approximation
            from sklearn.linear_model import LinearRegression
            model = LinearRegression()
            model.fit(X, y)
            
            # Predict next value
            last_sequence = data[-sequence_length:].reshape(1, -1)
            prediction = model.predict(last_sequence)[0]
            
            return np.clip(prediction, 0, 100)
            
        except Exception:
            return None
    
    def _generate_default_predictions(self, count: int) -> List[Dict]:
        """Generate default predictions when no historical data"""
        predictions = []
        base = 50.0
        
        for i in range(count):
            # Add some randomness but keep it centered
            prediction = base + np.random.normal(0, 15)
            prediction = np.clip(prediction, 0, 100)
            
            predictions.append({
                'predicted_result': float(prediction),
                'confidence': 40.0,
                'method': 'default_random',
                'contributing_methods': 0
            })
        
        return predictions
    
    def update_historical_data(self, new_results: List[float]):
        """Update historical results for pattern analysis"""
        self.historical_results.extend(new_results)
        
        # Keep only recent results to avoid memory issues
        if len(self.historical_results) > 1000:
            self.historical_results = self.historical_results[-500:]
        
        logger.info(f"ðŸ“Š Updated historical data: {len(self.historical_results)} results")
    
    def analyze_sharp_patterns(self, client_seed: str, server_seed: str, 
                             start_nonce: int, count: int = 1000) -> Dict:
        """Analyze patterns in HMAC results"""
        results = []
        
        for i in range(count):
            nonce = start_nonce + i
            result = self.calculate_stake_result(client_seed, server_seed, nonce)
            results.append(result)
        
        # Find sharp movements
        sharp_jumps = []
        sharp_drops = []
        
        for i in range(1, len(results)):
            diff = results[i] - results[i-1]
            
            if abs(diff) > 30:  # Sharp movement threshold
                if diff > 0:
                    sharp_jumps.append({
                        'nonce': start_nonce + i,
                        'from_value': results[i-1],
                        'to_value': results[i],
                        'magnitude': diff
                    })
                else:
                    sharp_drops.append({
                        'nonce': start_nonce + i,
                        'from_value': results[i-1],
                        'to_value': results[i],
                        'magnitude': abs(diff)
                    })
        
        return {
            'sharp_jumps': sharp_jumps,
            'sharp_drops': sharp_drops,
            'total_analyzed': count,
            'sharp_movement_frequency': (len(sharp_jumps) + len(sharp_drops)) / count * 100
        }

class PatternAnalyzer:
    """Advanced pattern analysis for massive datasets"""
    
    def __init__(self):
        self.pattern_memory = defaultdict(list)
        self.sequence_patterns = {}
        self.volatility_patterns = {}
        
    def analyze_massive_patterns(self, data: np.ndarray) -> Dict:
        """Analyze patterns in massive dataset"""
        logger.info(f"ðŸ” Analyzing patterns in {len(data)} data points...")
        
        patterns = {
            'distribution': self._analyze_distribution(data),
            'sequences': self._analyze_sequences(data),
            'volatility': self._analyze_volatility_windows(data),
            'cycles': self._detect_cycles(data),
            'correlations': self._analyze_correlations(data)
        }
        
        return patterns
    
    def _analyze_distribution(self, data: np.ndarray) -> Dict:
        """Analyze value distribution patterns"""
        zones = {
            'low': np.sum((data >= 0) & (data < 25)) / len(data) * 100,
            'medium_low': np.sum((data >= 25) & (data < 50)) / len(data) * 100,
            'medium_high': np.sum((data >= 50) & (data < 75)) / len(data) * 100,
            'high': np.sum((data >= 75) & (data <= 100)) / len(data) * 100
        }
        
        return {
            'zones': zones,
            'mean': float(np.mean(data)),
            'std': float(np.std(data)),
            'skewness': float(self._calculate_skewness(data)),
            'entropy': float(self._calculate_entropy(data))
        }
    
    def _analyze_sequences(self, data: np.ndarray, min_length: int = 3) -> Dict:
        """Find consecutive and oscillating patterns"""
        consecutive_up = []
        consecutive_down = []
        oscillating = []
        
        current_up = 0
        current_down = 0
        oscillation_count = 0
        last_direction = None
        
        for i in range(1, len(data)):
            diff = data[i] - data[i-1]
            
            if diff > 5:  # Significant up movement
                if current_up == 0:
                    current_up = 1
                current_up += 1
                current_down = 0
                
                direction = 'up'
                if last_direction == 'down':
                    oscillation_count += 1
                last_direction = direction
                
            elif diff < -5:  # Significant down movement
                if current_down == 0:
                    current_down = 1
                current_down += 1
                current_up = 0
                
                direction = 'down'
                if last_direction == 'up':
                    oscillation_count += 1
                last_direction = direction
                
            else:  # Neutral movement
                if current_up >= min_length:
                    consecutive_up.append(current_up)
                if current_down >= min_length:
                    consecutive_down.append(current_down)
                    
                current_up = 0
                current_down = 0
        
        return {
            'consecutive_up_sequences': consecutive_up,
            'consecutive_down_sequences': consecutive_down,
            'avg_up_length': float(np.mean(consecutive_up)) if consecutive_up else 0,
            'avg_down_length': float(np.mean(consecutive_down)) if consecutive_down else 0,
            'oscillation_frequency': oscillation_count / len(data) * 100
        }
    
    def _analyze_volatility_windows(self, data: np.ndarray, window_size: int = 50) -> Dict:
        """Analyze volatility patterns in sliding windows"""
        volatilities = []
        
        for i in range(0, len(data) - window_size, window_size // 2):
            window = data[i:i + window_size]
            volatility = float(np.std(window))
            volatilities.append(volatility)
        
        return {
            'volatilities': volatilities,
            'avg_volatility': float(np.mean(volatilities)),
            'max_volatility': float(np.max(volatilities)),
            'min_volatility': float(np.min(volatilities)),
            'volatility_trend': self._calculate_trend(volatilities)
        }
    
    def _detect_cycles(self, data: np.ndarray) -> Dict:
        """Detect cyclical patterns using FFT"""
        try:
            from scipy.fft import fft, fftfreq
            
            # Apply FFT
            fft_vals = fft(data - np.mean(data))
            freqs = fftfreq(len(data))
            
            # Find dominant frequencies
            power = np.abs(fft_vals)**2
            dominant_freq_idx = np.argsort(power)[-5:]  # Top 5 frequencies
            dominant_freqs = freqs[dominant_freq_idx]
            
            # Convert to periods
            periods = []
            for freq in dominant_freqs:
                if freq != 0:
                    period = 1 / abs(freq)
                    if period < len(data) / 2:  # Valid period
                        periods.append(float(period))
            
            return {
                'dominant_periods': sorted(periods),
                'strongest_period': float(min(periods)) if periods else 0,
                'cycle_strength': float(np.max(power[dominant_freq_idx]))
            }
            
        except ImportError:
            return {'error': 'scipy not available for cycle detection'}
    
    def _analyze_correlations(self, data: np.ndarray) -> Dict:
        """Analyze autocorrelations and lag patterns"""
        correlations = {}
        
        # Calculate autocorrelations for different lags
        for lag in [1, 5, 10, 25, 50]:
            if lag < len(data):
                correlation = np.corrcoef(data[:-lag], data[lag:])[0, 1]
                correlations[f'lag_{lag}'] = float(correlation) if not np.isnan(correlation) else 0
        
        return correlations
    
    def _calculate_skewness(self, data: np.ndarray) -> float:
        """Calculate skewness of distribution"""
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0
        return np.mean(((data - mean) / std) ** 3)
    
    def _calculate_entropy(self, data: np.ndarray, bins: int = 50) -> float:
        """Calculate entropy of value distribution"""
        hist, _ = np.histogram(data, bins=bins, density=True)
        hist = hist[hist > 0]  # Remove zero bins
        return -np.sum(hist * np.log(hist))
    
    def _calculate_trend(self, data: List[float]) -> str:
        """Calculate trend direction"""
        if len(data) < 2:
            return 'neutral'
            
        x = np.arange(len(data))
        slope = np.polyfit(x, data, 1)[0]
        
        if slope > 0.1:
            return 'increasing'
        elif slope < -0.1:
            return 'decreasing'
        else:
            return 'neutral'

class ThreeXORMiner:
    """
    3XOR Control Method from 'Computational records with aging hardware'
    Mines 32-zero-bit preimages with Bitcoin-miner logic to build A/B/C lists
    """
    
    def __init__(self):
        self.target_zeros = 8  # 32 zero bits = 8 hex chars
        self.target = '0' * self.target_zeros
        self.collision_cache = {}
        
    def mine_preimages(self, prefix: str, size: int = 2**16) -> List[str]:
        """Mine preimages with target zero bits"""
        logger.info(f"ðŸ”¨ Mining {size} preimages with prefix '{prefix}'...")
        
        preimages = []
        attempts = 0
        
        while len(preimages) < size and attempts < size * 100:
            # Generate random nonce
            nonce = os.urandom(16).hex()
            input_data = f"{prefix}{nonce}"
            
            # Calculate SHA-256
            hash_result = hashlib.sha256(input_data.encode()).hexdigest()
            
            # Check if it starts with target zeros
            if hash_result.startswith(self.target):
                preimages.append(nonce)
                
                if len(preimages) % 100 == 0:
                    logger.info(f"   Found {len(preimages)}/{size} preimages...")
            
            attempts += 1
        
        logger.info(f"âœ… Mined {len(preimages)} preimages in {attempts} attempts")
        return preimages
    
    def solve_3xor(self, A: List[str], B: List[str], C: List[str]) -> Tuple[str, str, str]:
        """Solve 3XOR problem: find a,b,c such that a XOR b XOR c = 0"""
        logger.info(f"ðŸ§® Solving 3XOR with lists A={len(A)}, B={len(B)}, C={len(C)}...")
        
        # Convert to integers for XOR operations
        A_ints = [int(a, 16) for a in A[:1000]]  # Limit for performance
        B_ints = [int(b, 16) for b in B[:1000]]
        C_ints = [int(c, 16) for c in C[:1000]]
        
        # Quadratic algorithm adaptation
        for i, a in enumerate(A_ints):
            for j, b in enumerate(B_ints):
                ab_xor = a ^ b
                
                # Look for matching c in C
                for k, c in enumerate(C_ints):
                    if ab_xor ^ c == 0:
                        logger.info(f"âœ… Found 3XOR solution: A[{i}] âŠ• B[{j}] âŠ• C[{k}] = 0")
                        return (A[i], B[j], C[k])
        
        logger.warning("âŒ No 3XOR solution found")
        return None
    
    def inject_synthetic_bias(self, rolls: np.ndarray, triplet: Tuple[str, str, str]) -> np.ndarray:
        """Inject synthetic bias using 3XOR triplet"""
        if not triplet:
            return rolls
        
        logger.info("ðŸŽ¯ Injecting synthetic bias using 3XOR triplet...")
        
        # Generate biased values from triplet
        bias_values = []
        for t in triplet:
            # Create HMAC with triplet element
            hmac_result = hmac.new(t.encode(), b'BIAS_INJECTION', hashlib.sha256).hexdigest()
            # Convert to dice roll
            hex_val = int(hmac_result[:8], 16)
            roll = (hex_val % 10000) / 100.0
            bias_values.append(roll)
        
        # Inject bias every 10000 rolls
        biased_rolls = rolls.copy()
        injection_interval = 10000
        
        for i in range(0, len(rolls), injection_interval):
            if i + 3 < len(biased_rolls):
                biased_rolls[i:i+3] = bias_values
        
        logger.info(f"âœ… Injected bias at {len(rolls) // injection_interval} points")
        return biased_rolls

class SupremeFeatureExtractor:
    """Extract features using top 10 elite pattern recognition methods"""
    
    def __init__(self):
        self.method_weights = {
            'nist_stats': 0.20,      # NIST Statistical Tests
            'markov_chains': 0.15,   # Markov Chains (order 3-5)
            'gap_analysis': 0.15,    # Gap/Run Analysis  
            'entropy_measures': 0.10, # Frequency/Entropy
            'correlation_matrix': 0.10, # Correlation Analysis
            'bayesian_inference': 0.10, # Bayesian Updates
            'time_series': 0.10,     # ARIMA Time-Series
            'neural_patterns': 0.05, # LSTM/GRU features
            'random_forest': 0.03,   # Random Forest features
            'genetic_algo': 0.02     # Genetic Algorithm features
        }
    
    def extract_nist_features(self, sequence: np.ndarray) -> List[float]:
        """NIST Statistical Tests: Chi-square, autocorrelation, runs test"""
        features = []
        
        # Chi-square test on bins
        bins = np.histogram(sequence, bins=10, range=(0, 100))[0]
        expected = len(sequence) / 10
        chi_square = np.sum((bins - expected) ** 2 / expected) if expected > 0 else 0
        features.append(chi_square)
        
        # Autocorrelation for lags 1-10
        autocorr_mean = 0
        for lag in range(1, min(11, len(sequence))):
            if len(sequence) > lag:
                corr = np.corrcoef(sequence[:-lag], sequence[lag:])[0, 1]
                autocorr_mean += corr if not np.isnan(corr) else 0
        features.append(autocorr_mean / 10)
        
        # Runs test
        median = np.median(sequence)
        runs = np.sum(np.diff(sequence > median) != 0) + 1
        features.append(runs / len(sequence) if len(sequence) > 0 else 0)
        
        return features
    
    def extract_markov_features(self, sequence: np.ndarray) -> List[float]:
        """Markov Chains: Transition matrices for orders 3-5"""
        features = []
        
        for order in [3, 4, 5]:
            if len(sequence) > order:
                # Discretize sequence
                discrete_seq = np.digitize(sequence, np.linspace(0, 100, 11))
                
                # Build transition matrix
                transitions = defaultdict(lambda: defaultdict(int))
                total_transitions = 0
                
                for i in range(len(discrete_seq) - order):
                    state = tuple(discrete_seq[i:i+order])
                    next_state = discrete_seq[i+order]
                    transitions[state][next_state] += 1
                    total_transitions += 1
                
                # Calculate entropy of transition probabilities
                entropy_sum = 0
                for state in transitions:
                    total = sum(transitions[state].values())
                    if total > 0:
                        probs = [count/total for count in transitions[state].values()]
                        entropy_sum += entropy(probs, base=2)
                
                features.append(entropy_sum / len(transitions) if transitions else 0)
            else:
                features.append(0)
        
        return features
    
    def extract_gap_features(self, sequence: np.ndarray) -> List[float]:
        """Gap/Run Analysis: Exponential fits, geometric distribution"""
        features = []
        
        if len(sequence) > 1:
            # Calculate gaps
            gaps = np.diff(sequence)
            features.extend([
                np.mean(gaps),
                np.std(gaps),
                np.min(gaps),
                np.max(gaps),
                np.median(gaps)
            ])
            
            # Streak analysis
            above_median = sequence > np.median(sequence)
            streaks = []
            current_streak = 1
            
            for i in range(1, len(above_median)):
                if above_median[i] == above_median[i-1]:
                    current_streak += 1
                else:
                    streaks.append(current_streak)
                    current_streak = 1
            
            if streaks:
                features.extend([
                    np.mean(streaks),
                    np.std(streaks),
                    np.max(streaks)
                ])
            else:
                features.extend([0, 0, 0])
        else:
            features.extend([0] * 8)
        
        return features
    
    def extract_entropy_features(self, sequence: np.ndarray) -> List[float]:
        """Frequency/Entropy: Shannon, min-entropy, conditional entropy"""
        features = []
        
        # Shannon entropy on bins
        bins = np.histogram(sequence, bins=20, range=(0, 100))[0]
        bins = bins[bins > 0]  # Remove empty bins
        if len(bins) > 0:
            shannon_ent = entropy(bins, base=2)
        else:
            shannon_ent = 0
        features.append(shannon_ent)
        
        # Min-entropy (maximum probability)
        if len(bins) > 0:
            min_ent = -np.log2(np.max(bins) / np.sum(bins))
        else:
            min_ent = 0
        features.append(min_ent)
        
        # Conditional entropy
        if len(sequence) > 1:
            # Discretize for conditional calculation
            discrete = np.digitize(sequence, np.linspace(0, 100, 11))
            cond_ent = 0
            
            for i in range(1, len(discrete)):
                prev_val = discrete[i-1]
                curr_val = discrete[i]
                # Simplified conditional entropy approximation
                cond_ent += np.log2(len(np.unique(discrete))) if len(np.unique(discrete)) > 0 else 0
            
            features.append(cond_ent / len(discrete))
        else:
            features.append(0)
        
        return features
    
    def extract_correlation_features(self, sequence: np.ndarray) -> List[float]:
        """Correlation Analysis: Pearson, Spearman, mutual information"""
        features = []
        
        if len(sequence) > 10:
            # Pearson correlation on windows
            window_size = min(10, len(sequence) // 2)
            correlations = []
            
            for i in range(len(sequence) - window_size):
                x = sequence[i:i+window_size]
                y = sequence[i+1:i+window_size+1]
                if len(x) == len(y) and len(x) > 1:
                    corr, _ = pearsonr(x, y)
                    if not np.isnan(corr):
                        correlations.append(corr)
            
            if correlations:
                features.extend([
                    np.mean(correlations),
                    np.std(correlations),
                    np.min(correlations),
                    np.max(correlations)
                ])
            else:
                features.extend([0, 0, 0, 0])
            
            # Spearman correlation
            if len(sequence) > 2:
                spear_corr, _ = spearmanr(sequence[:-1], sequence[1:])
                features.append(spear_corr if not np.isnan(spear_corr) else 0)
            else:
                features.append(0)
        else:
            features.extend([0] * 5)
        
        return features
    
    def extract_bayesian_features(self, sequence: np.ndarray) -> List[float]:
        """Bayesian Inference: Dirichlet priors, posterior updates"""
        features = []
        
        # Simulate Bayesian updating with Dirichlet prior
        alpha_prior = np.ones(10)  # Uniform prior for 10 bins
        
        # Update with observed data
        bins = np.histogram(sequence, bins=10, range=(0, 100))[0]
        alpha_posterior = alpha_prior + bins
        
        # Calculate posterior statistics
        posterior_mean = alpha_posterior / np.sum(alpha_posterior)
        features.extend([
            entropy(posterior_mean, base=2),  # Posterior entropy
            np.std(posterior_mean),           # Posterior uncertainty
            np.max(posterior_mean)            # Most probable bin
        ])
        
        return features
    
    def extract_time_series_features(self, sequence: np.ndarray) -> List[float]:
        """Time-Series Analysis: ARIMA-inspired features"""
        features = []
        
        if len(sequence) > 5:
            # First and second differences
            diff1 = np.diff(sequence)
            diff2 = np.diff(diff1)
            
            features.extend([
                np.mean(diff1),
                np.std(diff1),
                np.mean(diff2) if len(diff2) > 0 else 0,
                np.std(diff2) if len(diff2) > 0 else 0
            ])
            
            # Autocorrelation of residuals (simplified)
            if len(diff1) > 1:
                autocorr = np.corrcoef(diff1[:-1], diff1[1:])[0, 1]
                features.append(autocorr if not np.isnan(autocorr) else 0)
            else:
                features.append(0)
        else:
            features.extend([0] * 5)
        
        return features
    
    def extract_all_features(self, sequence: np.ndarray) -> np.ndarray:
        """Extract all features using top 10 methods"""
        all_features = []
        
        # Extract features from each method
        all_features.extend(self.extract_nist_features(sequence))
        all_features.extend(self.extract_markov_features(sequence))
        all_features.extend(self.extract_gap_features(sequence))
        all_features.extend(self.extract_entropy_features(sequence))
        all_features.extend(self.extract_correlation_features(sequence))
        all_features.extend(self.extract_bayesian_features(sequence))
        all_features.extend(self.extract_time_series_features(sequence))
        
        # Add neural, random forest, genetic algo placeholders
        all_features.extend([np.mean(sequence), np.std(sequence)])  # Neural features
        all_features.extend([len(np.unique(sequence)), np.median(sequence)])  # RF features
        all_features.extend([np.var(sequence)])  # Genetic features
        
        return np.array(all_features, dtype=np.float32)

class LSTMPredictor(nn.Module):
    """LSTM Neural Network for sequence prediction"""
    
    def __init__(self, input_size=1, hidden_size=256, num_layers=2, output_size=1):
        super(LSTMPredictor, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, output_size)
        )
        
    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])  # Use last output
        return out

class SupremePatternOracle:
    """
    The Supreme Pattern Recognition Oracle
    3XOR mining system with billion roll analysis + Real Stake HMAC integration
    """
    
    def __init__(self):
        print("ðŸ”® SUPREME PATTERN ORACLE INITIALIZING...")
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.billion_rolls = None
        self.pattern_cache = {}
        self.elite_patterns = []
        self.xor_miners = []
        
        # Real Stake integration
        self.real_stake_seeds = {
            'client': "3f95f77b5e864e15",
            'server': "3428e6f9695f8643802530f8694b75a4efd9f22e50cbf7d5f6a1e21ce0e8bb92",
            'current_nonce': 1629
        }
        
        # Advanced HMAC calculation system
        self.hmac_analyzer = HMACAnalyzer()
        
        # Advanced pattern analysis
        self.pattern_analyzer = PatternAnalyzer()
        
        # Feature extraction system
        self.feature_extractor = SupremeFeatureExtractor()
        
        # 3XOR Mining system
        self.miner = ThreeXORMiner()
        
        # Initialize empty prediction methods list (will be populated after methods are defined)
        self.prediction_methods = []
        
    def load_guardrails(self):
        """Load guardrails from JSON configuration"""
        try:
            with open('guardrails.json', 'r') as f:
                self.guardrails = json.load(f)
        except FileNotFoundError:
            # Create default guardrails
            self.guardrails = {
                "weights": [0.2, 0.15, 0.15, 0.1, 0.1, 0.1, 0.1, 0.05, 0.05, 0.05],
                "max_bet": 0.01,
                "stop_loss": 0.1,
                "min_conf": 0.55,
                "entropy_threshold": 1.5,
                "sim_only": True
            }
            with open('guardrails.json', 'w') as f:
                json.dump(self.guardrails, f, indent=2)
        
        logger.info(f"ðŸ“‹ Loaded guardrails: {self.guardrails}")
    
    def load_billion_rolls(self) -> np.ndarray:
        """Load 1 billion rolls from binary file"""
        logger.info("ðŸ“Š Loading 1 billion rolls from 'rolls_1e9.u16'...")
        
        try:
            # Load as uint16 and convert to dice rolls (0-99.99)
            rolls = np.fromfile('rolls_1e9.u16', dtype=np.uint16)
            rolls = (rolls % 10000) / 100.0  # Convert to 0-99.99 range
            
            logger.info(f"âœ… Loaded {len(rolls):,} rolls")
            logger.info(f"ðŸ“ˆ Range: {rolls.min():.2f} - {rolls.max():.2f}")
            logger.info(f"ðŸ“Š Mean: {rolls.mean():.2f}, Std: {rolls.std():.2f}")
            
            return rolls
            
        except FileNotFoundError:
            logger.error("âŒ 'rolls_1e9.u16' not found! Please ensure the billion roll dataset exists.")
            raise
    
    def train_oracle(self, force_retrain=False):
        """Train the Supreme Pattern Oracle (one-time training)"""
        
        # Check if models already exist
        if os.path.exists('oracle.pth') and not force_retrain:
            logger.info("ðŸ”® Oracle models already exist. Loading from disk...")
            self.load_trained_models()
            return
        
        logger.info("ðŸ”¥ TRAINING SUPREME PATTERN ORACLE...")
        logger.info("=" * 80)
        
        # Load billion rolls
        rolls = self.load_billion_rolls()
        
        # Step 1: 3XOR Mining and Bias Injection
        logger.info("â›ï¸ Step 1: 3XOR Mining and Bias Injection")
        A = self.miner.mine_preimages('ORACLE-A-', size=1000)
        B = self.miner.mine_preimages('ORACLE-B-', size=1000)
        C = self.miner.mine_preimages('ORACLE-C-', size=1000)
        
        triplet = self.miner.solve_3xor(A, B, C)
        if triplet:
            rolls = self.miner.inject_synthetic_bias(rolls, triplet)
        
        # Step 2: Feature Extraction
        logger.info("ðŸ” Step 2: Advanced Feature Extraction")
        
        window_size = 50
        step_size = 100  # Use every 100th window for performance
        
        X, y = [], []
        total_windows = (len(rolls) - window_size) // step_size
        
        for i in range(0, len(rolls) - window_size, step_size):
            if len(X) % 10000 == 0:
                progress = len(X) / total_windows * 100
                logger.info(f"   Progress: {progress:.1f}% ({len(X)}/{total_windows} windows)")
            
            window = rolls[i:i+window_size]
            features = self.feature_extractor.extract_all_features(window)
            target = rolls[i+window_size]
            
            X.append(features)
            y.append(target)
        
        X = np.array(X)
        y = np.array(y)
        
        logger.info(f"âœ… Extracted {len(X)} feature vectors with {X.shape[1]} features each")
        
        # Step 3: Data Preprocessing
        logger.info("ðŸ”§ Step 3: Data Preprocessing")
        
        # Handle NaN/inf values
        X = np.nan_to_num(X, nan=0, posinf=0, neginf=0)
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Scale features
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        logger.info(f"ðŸ“Š Training set: {X_train_scaled.shape}")
        logger.info(f"ðŸ“Š Test set: {X_test_scaled.shape}")
        
        # Step 4: Train Elite Models
        logger.info("ðŸ§  Step 4: Training Elite Model Ensemble")
        
        models = {
            'random_forest': RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42),
            'gradient_boost': GradientBoostingRegressor(n_estimators=100, max_depth=10, random_state=42),
            'mlp': MLPRegressor(hidden_layer_sizes=(256, 128, 64), max_iter=500, random_state=42),
            'linear': LinearRegression()
        }
        
        model_scores = {}
        
        for name, model in models.items():
            logger.info(f"   Training {name}...")
            start_time = time.time()
            
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
            
            mse = mean_squared_error(y_test, y_pred)
            r2 = model.score(X_test_scaled, y_test)
            
            model_scores[name] = {'mse': mse, 'r2': r2}
            
            training_time = time.time() - start_time
            logger.info(f"   âœ… {name}: MSE={mse:.3f}, RÂ²={r2:.3f}, Time={training_time:.1f}s")
        
        # Train LSTM
        logger.info("   Training LSTM...")
        lstm_model = self.train_lstm(X_train_scaled, y_train, X_test_scaled, y_test)
        models['lstm'] = lstm_model
        
        self.models = models
        
        # Step 5: Pattern Analysis and Storage
        logger.info("ðŸ” Step 5: Pattern Analysis and Storage")
        
        patterns = {
            'feature_importance': {},
            'model_scores': model_scores,
            'training_stats': {
                'total_samples': len(X),
                'features': X.shape[1],
                'training_time': time.time()
            },
            '3xor_triplet': triplet,
            'bias_injection': triplet is not None
        }
        
        # Get feature importance from Random Forest
        if hasattr(models['random_forest'], 'feature_importances_'):
            importance = models['random_forest'].feature_importances_
            patterns['feature_importance']['random_forest'] = importance.tolist()
        
        self.patterns = patterns
        
        # Step 6: Save Trained Models
        logger.info("ðŸ’¾ Step 6: Saving Oracle Models")
        
        self.save_trained_models()
        
        logger.info("=" * 80)
        logger.info("ðŸ† SUPREME PATTERN ORACLE TRAINING COMPLETE!")
        logger.info(f"ðŸŽ¯ Best Model Performance:")
        
        for name, scores in model_scores.items():
            logger.info(f"   {name}: MSE={scores['mse']:.3f}, RÂ²={scores['r2']:.3f}")
        
        logger.info("ðŸ”® The Oracle is ready to dominate!")
        
    def train_lstm(self, X_train, y_train, X_test, y_test):
        """Train LSTM neural network"""
        
        # Reshape for LSTM (batch_size, seq_len, input_size)
        X_train_lstm = torch.FloatTensor(X_train).unsqueeze(-1).to(device)
        y_train_lstm = torch.FloatTensor(y_train).to(device)
        X_test_lstm = torch.FloatTensor(X_test).unsqueeze(-1).to(device)
        y_test_lstm = torch.FloatTensor(y_test).to(device)
        
        # Initialize model
        model = LSTMPredictor(input_size=1, hidden_size=128, num_layers=2).to(device)
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        # Training loop
        epochs = 50
        batch_size = 64
        
        model.train()
        for epoch in range(epochs):
            total_loss = 0
            
            # Mini-batch training
            for i in range(0, len(X_train_lstm), batch_size):
                batch_X = X_train_lstm[i:i+batch_size]
                batch_y = y_train_lstm[i:i+batch_size]
                
                optimizer.zero_grad()
                outputs = model(batch_X).squeeze()
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
            
            if epoch % 10 == 0:
                avg_loss = total_loss / (len(X_train_lstm) // batch_size)
                logger.info(f"      Epoch {epoch}: Loss={avg_loss:.4f}")
        
        # Test the model
        model.eval()
        with torch.no_grad():
            test_outputs = model(X_test_lstm).squeeze()
            test_loss = criterion(test_outputs, y_test_lstm)
            logger.info(f"   âœ… LSTM: Test Loss={test_loss:.3f}")
        
        return model
    
    def save_trained_models(self):
        """Save all trained models and components"""
        
        # Save sklearn models and scaler
        joblib.dump({
            'random_forest': self.models['random_forest'],
            'gradient_boost': self.models['gradient_boost'],
            'mlp': self.models['mlp'],
            'linear': self.models['linear']
        }, 'oracle.pth')
        
        # Save LSTM model
        if 'lstm' in self.models:
            torch.save(self.models['lstm'].state_dict(), 'oracle_lstm.pth')
        
        # Save scaler
        with open('scaler.pkl', 'wb') as f:
            pickle.dump(self.scaler, f)
        
        # Save patterns
        with open('patterns.json', 'w') as f:
            json.dump(self.patterns, f, indent=2)
        
        logger.info("ðŸ’¾ All Oracle components saved successfully!")
    
    def load_trained_models(self):
        """Load pre-trained models from disk"""
        
        try:
            # Load sklearn models
            sklearn_models = joblib.load('oracle.pth')
            self.models.update(sklearn_models)
            
            # Load LSTM model
            if os.path.exists('oracle_lstm.pth'):
                lstm_model = LSTMPredictor(input_size=1, hidden_size=128, num_layers=2).to(device)
                lstm_model.load_state_dict(torch.load('oracle_lstm.pth', map_location=device))
                lstm_model.eval()
                self.models['lstm'] = lstm_model
            
            # Load scaler
            with open('scaler.pkl', 'rb') as f:
                self.scaler = pickle.load(f)
            
            # Load patterns
            with open('patterns.json', 'r') as f:
                self.patterns = json.load(f)
            
            logger.info("ðŸ”® Oracle models loaded successfully!")
            logger.info(f"ðŸ“Š Available models: {list(self.models.keys())}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to load Oracle models: {e}")
            raise
    
    def predict_next_roll(self, recent_rolls: List[float], server_hash: str = None, 
                         client_seed: str = None, nonce: int = None) -> Dict[str, Any]:
        """Predict next roll using ensemble of elite methods"""
        
        if not self.models or not self.scaler:
            raise ValueError("Oracle not trained! Call train_oracle() first.")
        
        # Extract features from recent rolls
        sequence = np.array(recent_rolls)
        features = self.feature_extractor.extract_all_features(sequence)
        
        # Scale features
        features_scaled = self.scaler.transform([features])
        
        # Get predictions from all models
        predictions = {}
        
        # Sklearn models
        for name, model in self.models.items():
            if name != 'lstm':
                pred = model.predict(features_scaled)[0]
                predictions[name] = pred
        
        # LSTM model
        if 'lstm' in self.models:
            with torch.no_grad():
                features_tensor = torch.FloatTensor(features_scaled).unsqueeze(-1).to(device)
                lstm_pred = self.models['lstm'](features_tensor).cpu().numpy()[0][0]
                predictions['lstm'] = lstm_pred
        
        # Ensemble prediction using guardrail weights
        weights = self.guardrails.get('weights', [0.25, 0.25, 0.25, 0.25])
        model_names = list(predictions.keys())
        
        ensemble_pred = 0
        total_weight = 0
        
        for i, name in enumerate(model_names):
            if i < len(weights):
                weight = weights[i]
                ensemble_pred += predictions[name] * weight
                total_weight += weight
        
        if total_weight > 0:
            ensemble_pred /= total_weight
        
        # Ensure prediction is in valid range
        ensemble_pred = np.clip(ensemble_pred, 0, 99.99)
        
        # Calculate confidence based on model agreement
        pred_values = list(predictions.values())
        confidence = max(0, 100 - (np.std(pred_values) * 10))  # Higher agreement = higher confidence
        
        # Apply guardrails
        min_conf = self.guardrails.get('min_conf', 0.55)
        if confidence < min_conf * 100:
            confidence = min_conf * 100
        
        # Check for 3XOR echo (anomaly detection)
        anomaly_detected = self.detect_3xor_echo(recent_rolls + [ensemble_pred])
        
        result = {
            'prediction': float(ensemble_pred),
            'confidence': float(confidence),
            'individual_predictions': {k: float(v) for k, v in predictions.items()},
            'ensemble_weight': total_weight,
            'anomaly_detected': anomaly_detected,
            'model_count': len(predictions),
            'guardrails_applied': True,
            'method_weights': dict(zip(model_names, weights[:len(model_names)])),
            'features_extracted': len(features)
        }
        
        # Add HMAC calculation if seeds provided
        if server_hash and client_seed and nonce is not None:
            try:
                result['hmac_calculation'] = self.calculate_hmac_prediction(
                    server_hash, client_seed, nonce
                )
            except Exception as e:
                result['hmac_error'] = str(e)
        
        return result
    
    def detect_3xor_echo(self, sequence: List[float]) -> bool:
        """Detect 3XOR echo patterns (simplified anomaly detection)"""
        
        if len(sequence) < 3:
            return False
        
        # Check for suspicious patterns that might indicate 3XOR bias
        # This is a simplified implementation
        
        # Look for exact triplet matches (highly unlikely in random data)
        for i in range(len(sequence) - 2):
            triplet = sequence[i:i+3]
            for j in range(i+3, len(sequence) - 2):
                other_triplet = sequence[j:j+3]
                if np.allclose(triplet, other_triplet, atol=0.01):
                    return True
        
        # Check entropy - too low might indicate bias
        entropy_val = entropy(np.histogram(sequence, bins=10)[0] + 1e-10)
        if entropy_val < self.guardrails.get('entropy_threshold', 1.5):
            return True
        
        return False
    
    def calculate_hmac_prediction(self, server_hash: str, client_seed: str, nonce: int) -> Dict[str, Any]:
        """Calculate HMAC-SHA256 prediction if server seed is revealed"""
        
        # For demonstration - in real use, would need actual server seed
        # This shows the structure for when server seed is revealed
        
        result = {
            'method': 'HMAC-SHA256',
            'input': f"{client_seed}:{nonce}",
            'server_hash': server_hash,
            'note': 'Requires revealed server seed for accurate calculation'
        }
        
        # If we had the actual server seed (not just hash), we could calculate:
        # hmac_result = hmac.new(server_seed.encode(), f"{client_seed}:{nonce}".encode(), hashlib.sha256).hexdigest()
        # prediction = (int(hmac_result[:8], 16) % 10000) / 100.0
        
        return result
    
    def visualize_patterns(self, recent_rolls: List[float], save_plots: bool = True):
        """Generate visualization plots for patterns"""
        
        if not recent_rolls:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ðŸ”® Supreme Pattern Oracle - Analysis Dashboard', fontsize=16)
        
        rolls = np.array(recent_rolls)
        
        # 1. Gap histogram
        if len(rolls) > 1:
            gaps = np.diff(rolls)
            axes[0, 0].hist(gaps, bins=20, alpha=0.7, color='blue')
            axes[0, 0].set_title('Gap Distribution')
            axes[0, 0].set_xlabel('Gap Size')
            axes[0, 0].set_ylabel('Frequency')
        
        # 2. Frequency heatmap
        bins = np.histogram(rolls, bins=10, range=(0, 100))[0]
        axes[0, 1].bar(range(10), bins, color='red', alpha=0.7)
        axes[0, 1].set_title('Frequency Distribution')
        axes[0, 1].set_xlabel('Bin (0-9 = 0-99.99)')
        axes[0, 1].set_ylabel('Count')
        
        # 3. Time series
        axes[1, 0].plot(rolls, color='green', alpha=0.7)
        axes[1, 0].set_title('Roll Sequence')
        axes[1, 0].set_xlabel('Roll Number')
        axes[1, 0].set_ylabel('Value')
        
        # 4. Autocorrelation
        if len(rolls) > 10:
            lags = range(1, min(11, len(rolls)))
            autocorrs = []
            
            for lag in lags:
                if len(rolls) > lag:
                    corr = np.corrcoef(rolls[:-lag], rolls[lag:])[0, 1]
                    autocorrs.append(corr if not np.isnan(corr) else 0)
            
            axes[1, 1].bar(lags, autocorrs, color='purple', alpha=0.7)
            axes[1, 1].set_title('Autocorrelation')
            axes[1, 1].set_xlabel('Lag')
            axes[1, 1].set_ylabel('Correlation')
        
        plt.tight_layout()
        
        if save_plots:
            plt.savefig('oracle_patterns.png', dpi=150, bbox_inches='tight')
            logger.info("ðŸ“Š Pattern visualization saved as 'oracle_patterns.png'")
        
        return fig

# Main execution
if __name__ == '__main__':
    print("ðŸ”¥" * 40)
    print("SUPREME PATTERN ORACLE - SHA-256 DOMINATION ENGINE")
    print("ðŸ”¥" * 40)
    
    # Initialize the Oracle
    oracle = SupremePatternOracle()
    
    # Train the Oracle (one-time only)
    oracle.train_oracle()
    
    # Test prediction
    test_rolls = [45.23, 67.89, 34.56, 78.12, 56.78, 89.34, 23.45, 67.89, 45.67, 78.23]
    
    print("\nðŸ§ª Testing Oracle Prediction...")
    prediction = oracle.predict_next_roll(test_rolls)
    
    print(f"ðŸ”® Prediction: {prediction['prediction']:.2f}")
    print(f"ðŸŽ¯ Confidence: {prediction['confidence']:.1f}%")
    print(f"ðŸ¤– Models Used: {list(prediction['individual_predictions'].keys())}")
    print(f"âš ï¸ Anomaly Detected: {prediction['anomaly_detected']}")
    
    # Generate visualizations
    oracle.visualize_patterns(test_rolls)
    
    print("\nðŸ† SUPREME PATTERN ORACLE READY FOR DOMINATION!")
    print("ðŸ”® The Oracle has ascended to ultimate pattern mastery!")